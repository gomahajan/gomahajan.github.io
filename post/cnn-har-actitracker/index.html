<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.25.1" />
  <meta name="author" content="Gaurav Mahajan">
  <meta name="description" content="PhD. Student">

  
  
  
    
  
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.0/css/academicons.min.css" integrity="sha512-GGGNUPDhnG8LEAEDsjqYIQns+Gu8RBs4j5XGlxl7UfRaZBhCCm5jenJkeJL8uPuOXGqgl8/H1gjlWQDRjd3cUQ==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather%7CRoboto+Mono">
  <link rel="stylesheet" href="/css/hugo-academic.css">
  
  <link rel="stylesheet" href="/css/custom.css">
  

  

  <link rel="alternate" href="https://gomahajan.github.io/index.xml" type="application/rss+xml" title="Gaurav Mahajan">
  <link rel="feed" href="https://gomahajan.github.io/index.xml" type="application/rss+xml" title="Gaurav Mahajan">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://gomahajan.github.io/post/cnn-har-actitracker/">

  

  <title>Human Activity Recognition using Convolution Neural Network | Gaurav Mahajan</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Gaurav Mahajan</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#news">
            
            <span>News</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Human Activity Recognition using Convolution Neural Network</h1>
    

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2017-08-20 00:00:00 &#43;0000 UTC" itemprop="datePublished">
      Sun, Aug 20, 2017
    </time>
  </span>

  

  
  
  
  <span class="article-tags">
    <i class="fa fa-tags"></i>
    
    <a href="/tags/human-activity-recognition">human-activity-recognition</a
    >, 
    
    <a href="/tags/tensorflow">tensorflow</a
    >, 
    
    <a href="/tags/convolution-neural-network">convolution-neural-network</a
    >
    
  </span>
  
  

  
  

  

</div>

    <div class="article-style" itemprop="articleBody">
      <p>In this post<sup class="footnote-ref" id="fnref:1"><a class="footnote" href="#fn:1">1</a></sup>, we will discuss how to build a architecture for Human Activity Recognition using Convolution Neural Network. <a href="https://github.com/gomahajan/har-actitracker">Link to code</a></p>

<p></p>

<h1 id="python-libraries-used">Python Libraries Used</h1>

<ol>
<li>TensorFlow</li>
<li>Pandas</li>
<li>Numpy</li>
<li>Scipy</li>
<li>Matplotlib</li>
</ol>

<h1 id="dataset">Dataset</h1>

<p>We are going to build a architecture which recognizes human activities like walking, lying down, standing, sitting, jogging etc. based on accelerometer data. We will use the Actitracker dataset from <a href="http://www.cis.fordham.edu/wisdm/dataset.php">Wireless Sensor Data Mining Lab</a>.</p>

<p>Data for some activities in the dataset:</p>

<p><figure><img src="/img/har-cnn-actitracker/walking.png" alt=""></figure>
<figure><img src="/img/har-cnn-actitracker/lying-down.png" alt=""></figure></p>

<h1 id="architecture">Architecture</h1>

<p>Our architecture consists of multiple Depthwise Convolution Neural Networks (D-CONV), Max POOL and RELU layers, followed by fully connected neural network (FC) with a softmax classifier to get the class probabilities.</p>

<p>[D-CONV -&gt; RELU] -&gt; POOL -&gt; [D-CONV -&gt; RELU] -&gt; FC</p>

<p>If you haven't heard of Depthwise Convolution Neural Networks, they are similar to normal Convolution Neural Networks except the filters are applied to each channel separately. So, a Convolution Neural Network which has input tensor of shape [batch, in_height, in_width, in_channels] and a filter tensor of shape [filter_height, filter_width, in_channels, out_channels] will output a tensor of shape [batch, out_height, out_width, out_channels]. A Depthwise Convolution Neural Network which has input tensor of shape [batch, in_height, in_width, in_channels] and a filter tensor of shape [filter_height, filter_width, in_channels, channel_multiplier] will output a tensor of shape [batch, out_height, out_width, in_channels*channel_multiplier] as it will separately apply channel_multiplier number of filters to each in_channel.</p>

<h1 id="building-the-architecture-in-tensorflow">Building the architecture in TensorFlow</h1>

<p>We create placeholder variables for our input and output values. In TensorFlow, using 'None' as a dimension allows the variable to take any number of rows.</p>

<pre><code class="language-python">self.X = tf.placeholder(tf.float32, shape=[None, input_height, input_width, in_channels])
self.Y = tf.placeholder(tf.float32, shape=[None, num_labels])
</code></pre>

<p>Next, we create a Depthwise Convolution Neural Network (D-CNN) which has input tensor of shape [batch, in_height, in_width, in_channels] and a filter tensor of shape [filter_height, filter_width, in_channels, channel_multiplier] and will output a tensor of shape [batch, out_height, out_width, in_channels*channel_multiplier].</p>

<pre><code class="language-python">filter = weight_variable([1, filter_width, in_channels, channels_multiplier])
depthwise_conv2d = tf.nn.depthwise_conv2d(input, filter, [1, 1, 1, 1], padding='VALID')
</code></pre>

<p>We follow the D-CNN with a RELU layer and add a bias for each channel.</p>

<pre><code class="language-python">biases = bias_variable([channels_multiplier * in_channels])
tf.nn.relu(tf.add(depthwise_conv2d, biases))
</code></pre>

<p>We then add a max POOL layer which performs the max pooling over the window of ksize=[1, 1, kernel_size, 1] and uses a stride of [1, 1, stride_size, 1].
Note: We are performing the max pooling and stride only in the dimension of input_width. We do not want to pool across the channels or batch entries as we want to keep them independent. Also, input_height is 1 for D-CNN.</p>

<pre><code class="language-python">p = tf.nn.max_pool(x, ksize=[1, 1, kernel_size, 1],
                          strides=[1, 1, stride_size, 1], padding='VALID')
</code></pre>

<p>We then add another D-CNN with filter tensor of shape [1, filter_width_2, in_channels_2, channel_multiplier_2]. in_channels_2 is equal to channels_multiplier * in_channels since D-CNN multiplies the number of channels by the channels_multiplier and our pooling preserved the
channel size.
Note: We, however, have to be careful when choosing the filter_width_2 as it should not be more than POOL layer's output width.</p>

<pre><code class="language-python">assert filter_width_2 &lt;= p.shape[2], &quot;Filter width 2 should be less than input width 2&quot;
c = apply_depthwise_conv(p, filter_width_2, channels_multiplier * in_channels, channels_multiplier_2)
</code></pre>

<p>We flatten the output from the second D-CNN and pass it into a neural network.</p>

<pre><code class="language-python">shape = c.get_shape().as_list()
c_flat = tf.reshape(c, [-1, shape[1] * shape[2] * shape[3]])

assert shape[3] == channels_multiplier * in_channels * channels_multiplier_2

f_weights_l1 = weight_variable([shape[1] * shape[2] * shape[3], num_hidden])
f_biases_l1 = bias_variable([num_hidden])
f = tf.nn.tanh(tf.add(tf.matmul(c_flat, f_weights_l1), f_biases_l1))
</code></pre>

<p>We then add a softmax classifier which outputs the class probabilities and loss.</p>

<pre><code class="language-python">out_weights = weight_variable([num_hidden, num_labels])
out_biases = bias_variable([num_labels])
self.y_ = tf.nn.softmax(tf.matmul(f, out_weights) + out_biases)
self.loss = -tf.reduce_sum(self.Y * tf.log(self.y_))
</code></pre>

<h1 id="preprocessing-data">Preprocessing data</h1>

<p>Using pandas library, we can read the data from the WISDM dataset using column names as indices for the returned DataFrame.</p>

<pre><code class="language-python">column_names = ['user-id', 'activity', 'timestamp', 'x-axis', 'y-axis', 'z-axis']
data = pd.read_csv(file_path, header=None, names=column_names, comment=';')
</code></pre>

<p>We then drop the rows which have 'nan' entries and reduce the size in case we want to use only a certain percentage of the dataset <sup class="footnote-ref" id="fnref:2"><a class="footnote" href="#fn:2">2</a></sup>.</p>

<pre><code class="language-python">data = data.dropna(axis=0, how='any')
data = data[0:(usage * data.shape[0]) // 100]
</code></pre>

<p>We normalize the data independently from accelerometer along the x-axis, y-axis and z-axis.</p>

<pre><code class="language-python">def normalize(dataset):
   mu = np.mean(dataset, axis=0)
   sigma = np.std(dataset, axis=0)
   return (dataset - mu) / sigma

dataset['x-axis'] = math.normalize(dataset['x-axis'])
dataset['y-axis'] = math.normalize(dataset['y-axis'])
dataset['z-axis'] = math.normalize(dataset['z-axis'])
</code></pre>

<p>Next, we segment the data into [windows_size, in_channels] blocks and we choose the label as the most occurring label in the window.</p>

<pre><code class="language-python">def create_segments(data, window_size=90):
    segments = np.empty((0, window_size, 3))
    labels = np.empty((0))
    for (start, end) in windows(data['timestamp'], window_size):
        x = data[&quot;x-axis&quot;][start:end]
        y = data[&quot;y-axis&quot;][start:end]
        z = data[&quot;z-axis&quot;][start:end]
        if (len(data['timestamp'][start:end]) == window_size):
            segments = np.vstack([segments, np.dstack([x, y, z])])
            labels = np.append(labels, stats.mode(data[&quot;activity&quot;][start:end])[0][0])
    return segments, labels

segments, labels = util.create_segments(dataset)
</code></pre>

<p>We then one hot encode the labels and reshape the segments into [1, windows_size, in_channels] blocks.</p>

<pre><code class="language-python">labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)
reshaped_segments = segments.reshape(len(segments), 1, 90, 3)
</code></pre>

<p>We do a 70:30 split of the data into train:test sets.</p>

<pre><code class="language-python">train_test_split = np.random.rand(len(reshaped_segments)) &lt; 0.70
train_x = reshaped_segments[train_test_split]
train_y = labels[train_test_split]
test_x = reshaped_segments[~train_test_split]
test_y = labels[~train_test_split]
</code></pre>

<h1 id="training-and-evaluating-the-model">Training and evaluating the model</h1>

<p>We batch the training data into sets of 10 and use gradient descent for learning weights.</p>

<pre><code class="language-python">learning_rate = 0.0001
training_epochs = 8
batch_size = 10
total_batches = train_x.shape[0] // batch_size
optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(self.loss)

correct_prediction = tf.equal(tf.argmax(self.y_, 1), tf.argmax(self.Y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

cost_history = np.empty(shape=[1], dtype=float)
</code></pre>

<p>We create a TensorFlow session, initialize the variables and train our model.
We print the accuracy on the training set for each epoch.</p>

<pre><code class="language-python">with tf.Session() as session:
    tf.initialize_all_variables().run()
    for epoch in range(training_epochs):
        for b in range(total_batches):
            offset = (b * batch_size) % (train_y.shape[0] - batch_size)
            batch_x = train_x[offset:(offset + batch_size), :, :, :]
            batch_y = train_y[offset:(offset + batch_size), :]
            _, loss_value = session.run([optimizer, self.loss], feed_dict={self.X: batch_x, self.Y: batch_y})
            cost_history = np.append(cost_history, loss_value)
        print(&quot;Epoch: &quot;, epoch, &quot; Training Loss: &quot;, loss_value, &quot; Training Accuracy: &quot;,
              session.run(accuracy, feed_dict={self.X: train_x, self.Y: train_y}))
</code></pre>

<p>We then get our accuracy on the test set.</p>

<pre><code class="language-python">print(&quot;Testing Accuracy:&quot;, session.run(accuracy, feed_dict={self.X: test_x, self.Y: test_y}))
</code></pre>
<div class="footnotes">

<hr>

<ol>
<li id="fn:1">Inspired from a similar <a href="https://github.com/aqibsaeed/Human-Activity-Recognition-using-CNN">post</a> by Aaqib Saeed
 <a class="footnote-return" href="#fnref:1"><sup>^</sup></a></li>
<li id="fn:2">Helps when you are testing your architecture and do not want the &quot;immenseness&quot; of your data to slow you.
 <a class="footnote-return" href="#fnref:2"><sup>^</sup></a></li>
</ol>
</div>
    </div>
  </div>

</article>

<div class="container">
  <nav>
  <ul class="pager">
    
    <li class="previous"><a href="https://gomahajan.github.io/post/finding-regression-function/"><span
      aria-hidden="true">&larr;</span> Finding Regression Function</a></li>
    

    
  </ul>
</nav>

</div>

<div class="article-container">
  
<section id="comments">
  <div id="disqus_thread">
    <div id="disqus_thread"></div>
<script>
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "gmahajanml" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
  </div>
</section>


</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 Gaurav Mahajan 

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js" integrity="sha512-jGsMH83oKe9asCpkOVkBnUrDDTp8wl+adkB2D+//JtlxO4SrLoJdhbOysIFQJloQFD+C4Fl1rMsQZF76JjV0eQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.2/imagesloaded.pkgd.min.js" integrity="sha512-iHzEu7GbSc705hE2skyH6/AlTpOfBmkx7nUqTLGzPYR+C1tRaItbRlJ7hT/D3YQ9SV0fqLKzp4XY9wKulTBGTw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js" integrity="sha512-Z5heTz36xTemt1TbtbfXtTq5lMfYnOkXM2/eWcTTiLU01+Sw4ku1i7vScDc8fWhrP2abz9GQzgKH5NGBLoYlAw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/plugins/ScrollToPlugin.min.js" integrity="sha512-CDeU7pRtkPX6XJtF/gcFWlEwyaX7mcAp5sO3VIu/ylsdR74wEw4wmBpD5yYTrmMAiAboi9thyBUr1vXRPA7t0Q==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ 
        tex2jax: { 
              inlineMath: [['$','$'], ['\\(','\\)']],
              displayMath: [['$$','$$']],
              processEscapes: true,
              processEnvironments: true
            },
        TeX: {
          equationNumbers: {
              autoNumber: "AMS"
            }
        }
        });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

