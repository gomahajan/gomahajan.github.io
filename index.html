<!DOCTYPE html>
<html lang="en">

<head>
    <title>Gaurav Mahajan</title>
    <meta name="theme-color" content="#444A60" />
    <meta name="description"
        content="PhD Student at UCSD theory group. Pursuing theoretical research in learning advised by Sanjoy Dasgupta and Shachar Lovett.">
    <link rel="stylesheet" type="text/css" href="css/style.css?v=2.1">
    <link
        href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,200,900italic,900,700italic,700,600italic,600,400italic,300italic,300,200italic'
        rel='stylesheet' type='text/css'>
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <main>
        <div class="dtable">
            <div class="half pad20" style="height: 60px;">
                <a href="./">
                    <h1 class="top-header" style="font-weight: 500; margin: 0px;">Gaurav Mahajan</h1>
                </a>
                <div class="hidden" style="text-align: left;"> <b style="font-weight: 700;">Email:</b>
                    gmahajan@eng.ucsd.edu</div><br>
            </div>
            <div class="hidden" style="float: left; padding: 15px 50px 0px 30px; width: 42%">
                <p style="text-align: right; margin: 5px;">
                    Office 4230,<br> CSE Building<br>
                    La Jolla, CA, 92092
                </p>
            </div>
        </div>
        <hr>
        <article>
            <div style="display: table; margin: 0px 0px 30px 0px;">
                <div class="half margin30" style="float: left;">
                    <img src="images/p2cropped.jpg" alt="Gaurav's photo" id="photo"></img>
                </div>
                <div class="half margin30" style="float: left;">
                    <p style="margin: 70px 0px 0px 0px;">
                        I will be joining Yale as FDS postdoc in May 2023.<br> <br>
                        I am broadly interested in theoretical computer science and machine learning.
                        Previously, I completed my PhD in the <a href="https://cstheory.ucsd.edu/home.html">theory
                            group</a> at
                        UCSD advised by <a href="https://cseweb.ucsd.edu/~dasgupta/">Sanjoy Dasgupta</a> and
                        <a href="https://cseweb.ucsd.edu/~slovett/">Shachar Lovett</a>. I have spent some fun summers at Microsoft Research, Institute for Advanced Study
                        and Simons Institute.
                        <br><br> In the distant past, I worked at <a
                            href="https://powerapps.microsoft.com/en-us/">Microsoft</a> and received a
                        BS-MS from Indian Institute of Technology, Delhi (IITD).
                        <br>
                        <br>
                        See <a
                            href="https://scholar.google.com/citations?hl=en&user=3kvq284AAAAJ&view_op=list_works&sortby=pubdate">[Google
                            Scholar]</a>
                        and <a href="publications.html">here</a> for full list of publications.
                    </p>
                </div>
            </div>
            <div style="display: table;">
                <div class="margin30">
                    <h1>Selected Publications<a href="#footnote">&ast;</a></h1>
                    <ol>
                        <li>
                            <p>
                                <a href="https://arxiv.org/abs/2302.14753">Learning Hidden Markov Models Using
                                    Conditional Samples</a>
                                <br> with S.M. Kakade, A. Krishnamurthy, C. Zhang
                            </p>
                            <div class="abstract">
                                Hidden Markov Models are cryptographically hard to learn in the standard setting where
                                one has access to i.i.d. samples of
                                observation sequences. We depart from this setup and consider an interactive access
                                model,
                                in which the algorithm can query for samples from the conditional distributions of the
                                HMMs. We
                                show that interactive access to the HMM enables computationally efficient learning
                                algorithms, thereby
                                bypassing cryptographic hardness.
                            </div>
                            <p></p>
                        </li>
                        <li>
                            <p>
                                <a href="https://arxiv.org/abs/2202.05444">Computational-Statistical Gaps in
                                    Reinforcement Learning</a>
                                <br> with D. Kane, S. Lui, S. Lovett
                            </p>
                            <div class="abstract">
                                This work resolves an open problem on designing computationally efficient algorithms for linear
                                RL setting (linear Q&ast;, linear V&ast;, linear Q&ast; &#38; V&ast;, &hellip;) by
                                showing that unless NP=RP, no polynomial time algorithm exists for any of these
                                settings. This is in contrast to the corresponding statistical problem, which was shown
                                to be solvable in polynomial sample complexity following a line of dedicated work from
                                the community. See this <a href="talks/ttic0607.mp4" target="_blank">
                                    <font color="red">talk</font>
                                </a> for a survey on this area.
                            </div>
                            <p></p>
                        </li>
                        <li>
                            <p>
                                <a href="https://arxiv.org/abs/1908.00261">Optimality and Approximation with
                                    Policy
                                    Gradient Methods in Markov Decision
                                    Processes</a>
                                <br> with A. Agarwal, S. M. Kakade, J. D. Lee
                            </p>
                            <div class="abstract">
                                This work presents the first global convergence results for policy gradient methods like
                                vanilla policy gradient (w/wo regularization) and natural policy gradient. See this <a
                                    href="https://www.youtube.com/watch?v=tToomczBvMM&ab_channel=SimonsInstitute"
                                    target="_blank">
                                    <font color="red">talk</font>
                                </a> from Sham summarizing the results from this work.
                            </div>
                            <p></p>
                        </li>
                    </ol>
                </div>
            </div>

            <div style="display: table;">
                <div class="margin30">
                    <h1>Talks</h1>
                    <div style="padding-bottom: 0px;">
                        <ol>
                            <li style="margin-top: 0.5em;
                            margin-bottom: 0.5em;">Computational-Statistical Gaps in
                                Reinforcement Learning
                                <ol>
                                    <li>
                                        Microsoft Research New York Seminar
                                    </li>
                                    <li>
                                        Yale Foundations of Data Science Seminar
                                    </li>
                                    <li>
                                        EnCORE Fall Retreat
                                    </li>
                                    <li>
                                        TTIC Machine Learning Seminar Series
                                    </li>
                                    <li>
                                        UCLA Big Data and Machine Learning weekly seminar
                                    </li>
                                    <li>
                                        Brown Robotics Group (George
                                        Konidaris's group)
                                    </li>
                                    <li>
                                        Berkeley RL Reading Group (Jiantao Jiao's group)
                                    </li>
                            </li>
                        </ol>
                        </li>
                        <li style="margin-top: 0.5em;
                        margin-bottom: 0.5em;">Equivalence between Realizable and Agnostic
                            Learning
                            <ol>
                                <li> Cornell
                                    Theory Seminar
                                </li>
                                <li>
                                    MSR New York ML Reading Group
                                </li>
                            </ol>
                        </li>
                        <li style="margin-top: 0.5em;
                        margin-bottom: 0.5em;">Theory
                            of Generalization in Reinforcement Learning
                            <ol>
                                <li>
                                    RL
                                    Theory Seminar
                                </li>
                                <li>
                                    UCSD AI
                                    Seminar
                                </li>
                                <li>
                                    UCSD
                                    Theory
                                    Seminar
                                </li>
                        </li>
                        </ol>
                        </ol>
                    </div>
                </div>
            </div>

            <div class="margin30">
                <h1>Professional Services</h1>
                <ol>
                    <li>
                        Reviewer: ICLR (2022); WORLT (2021); Neurips (2021); ICML (2021, 2020), JMLR (2022, 2021,
                        2020)
                    </li>
                </ol>
                <br>
                <br>
                <br>
                <p id="footnote" style="padding: 20px 0px 50px 0px;"> &ast; Authors are listed in alphabetical
                    order,
                    following the convention in mathematics
                    and theoretical computer science.</p>
            </div>
        </article>
    </main>
</body>

</html>