<!DOCTYPE html>
<html lang="en">

<head>
    <title>Gaurav Mahajan</title>
    <meta name="theme-color" content="#317EFB" />
    <meta name="description" content="PhD Student at UCSD theory group. Pursuing theoretical research in learning advised by Sanjoy Dasgupta and Shachar Lovett.">
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<main>
    <div id="header">
        <img src="images/p2cropped.jpg" alt="Gaurav's photo" id="photo"></img>
        <br>
        <br>
        <br>
        <div class="bio">
            <h1 class="top-header">Gaurav Mahajan</h1>
            <p>
                I am a 4th year PhD student in the <a href="https://cstheory.ucsd.edu/home.html">theory group</a> at UCSD, where I am advised by <a href="https://cseweb.ucsd.edu/~dasgupta/">Sanjoy Dasgupta</a> and <a href="https://cseweb.ucsd.edu/~slovett/">Shachar Lovett</a>.
                Before that, I worked at <a href="https://powerapps.microsoft.com/en-us/">Microsoft</a> for three years. I received a BS and MS in Mathematics and Computing from Indian Institute of Technology, Delhi (IITD) advised by <a href="https://scholar.google.com/citations?hl=en&user=cs1R7C0AAAAJ">Subiman Kundu</a>.
            </p>
            <p>
                In Fall 2019, I was a short term scholar at <a href="https://www.math.ias.edu/sp/Optimization_Statistics_and_Theoretical_Machine_Learning"> Institute for Advanced Study</a>. In Summer 2019, I was a visiting graduate student at <a href="https://simons.berkeley.edu/programs/dl2019">Simons Institute</a>.
            </p>
            <div class="backemail bottom-links">ude.dscu.gne (ta) najahamg  |  <a href="https://scholar.google.com/citations?user=3kvq284AAAAJ">[ralohcS elgooG]</a></div><br>
        </div>
    </div>
    <article>
        <p>
            I am broadly interested in questions related to learning and have recently worked on problems related to reinforcement learning,  active learning and unsupervised learning. 
        </p>
        <h1>Publications</h1>
        <ol>
            <li>
                <p>
                    <b>Bilinear Classes: A Structural Framework for Provable Generalization in RL</b>
                    <br> <i> with Simon S. Du, Sham M. Kakade, Jason D. Lee, Shachar Lovett, Wen Sun and Ruosong Wang
                    <br> Accepted to the 38th International Conference on Machine Learning (ICML 2021), Long Talk.</i>
                    <br> <a href="https://arxiv.org/abs/2103.10897">arxiv</a>
                </p>
                <p></p>
            </li>
            <li>
                <p>
                    <b>On the Theory of Policy Gradient Methods: Optimality, Approximation, and Distribution Shift</b>
                    <br> <i>with Alekh Agarwal, Sham Kakade and Jason Lee
                    <br> Accepted to the Journal of Machine Learning Research (JMLR 2020).</i>
                    <br> <a href="https://arxiv.org/abs/1908.00261">arxiv</a>
                </p>
                <p></p>
            </li>
            <li>
                <p>
                    <b>Q-learning with Function Approximation in Deterministic Systems: Tight Bounds on Approximation Error and Sample Complexity</b> 
                    <br> <i>with Simon Du, Jason Lee and Ruosong Wang</i>
                    <br> <i>Accepted to the 34th Annual Conference on Neural Information Processing Systems (NeurIPS 2020).</i>
                    <br> <a href="https://arxiv.org/abs/2002.07125">arxiv</a> | <a href="https://nips.cc/virtual/2020/protected/poster_fd5c905bcd8c3348ad1b35d7231ee2b1.html">talk</a>
                </p>
                <p></p>
            </li>
            <li>
                <p>
                    <b>Optimality and Approximation with Policy Gradient Methods in Markov Decision Processes</b>
                    <br> <i>with Alekh Agarwal, Sham Kakade and Jason Lee
                    <br> Accepted to the 33rd Annual Conference on Learning Theory (COLT 2020).</i>
                    <br> <a href="https://arxiv.org/abs/1908.00261">arxiv</a> | <a href="https://www.youtube.com/watch?v=ZGz57lbOK3w">talk</a> | <a href="https://www.youtube.com/watch?v=ZGz57lbOK3w">sham's talk</a>
                </p>
                <p></p>
            </li>
            <li>
                <p>
                    <b>Point Location and Active Learning: Learning Halfspaces Almost Optimally</b>
                    <br> <i>with Max Hopkins, Daniel Kane And Shachar Lovett
                    <br> Accepted to the 61st Annual Symposium on Foundations of Computer Science (FOCS 2020).</i>
                    <br> <a href="https://arxiv.org/abs/2004.11380">arxiv</a> | <a href="https://www.youtube.com/watch?v=ETNMFJjBrpc">shachar's talk</a> | <a href="https://www.youtube.com/watch?v=FqtvnlmWyjI">max's talk</a> 
                </p>
                <p></p>
            </li>
            <li>
                <p>
                    <b>Noise-tolerant, Reliable Active Classification with Comparison Queries</b>
                    <br> <i>with Max Hopkins, Daniel Kane And Shachar Lovett
                    <br> Accepted to the 33rd Annual Conference on Learning Theory (COLT 2020).</i>
                    <br><a href="https://arxiv.org/abs/2001.05497">arxiv</a> | <a href="https://www.youtube.com/watch?v=gKLFBeaWBSs">max's talk</a>
                </p>
                <p></p>
            </li>
        </ol>
    </article>
</main>

</html>