<!DOCTYPE html>
<html lang="en">

<head>
    <title>Gaurav Mahajan</title>
    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="css/style.css?v=1.1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <main>
        <div class="dtable">
            <div class="half pad20" style="height: 60px;">
                <a href="./">
                    <h1 class="top-header" style="font-weight: 500; margin: 0px;">Gaurav Mahajan</h1>
                </a>
                <div class="hidden" style="text-align: left;"> <b style="font-weight: 700;">Email:</b>
                    gmahajan@eng.ucsd.edu</div><br>
            </div>
            <div class="hidden" style="float: left; padding: 15px 50px 0px 30px; width: 42%">
                <p style="text-align: right; margin: 5px;">
                    Office 4230,<br> CSE Building<br>
                    La Jolla, CA, 92092
                </p>
            </div>
        </div>
        <hr>
        <article class="margin50">
            <div style="width: fit-content;">
                <!-- <h1 style="margin: 50px 0px 0px 0px;">Full Publication List</h1> -->
                <h1 style="margin: 50px 0px 0px 0px;">Publications<a href="#footnote">&ast;</a></h1>
                <ol style="list-style-type:decimal">
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2302.14753">Learning Hidden Markov Models Using Conditional Samples</a> <span class='options'> Preprint </span>
                            <br> <i>with S.M. Kakade, A. Krishnamurthy and C. Zhang.
                            </i>
                            <br> <a href="https://arxiv.org/abs/2302.14753">arxiv</a> 
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2302.12940">Exponential Hardness of Reinforcement Learning with Linear Function Approximation</a> <span class='options'> Preprint </span>
                            <br> <i>with D. Kane, S. Liu, S. Lovett, C. Szepesvari and G. Weisz
                            </i>
                            <br> <a href="https://arxiv.org/abs/2302.12940">arxiv</a> 
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2302.06285">Do PAC-Learners Learn the Marginal Distribution?</a> <span class='options'> Preprint </span>
                            <br> <i>with M. Hopkins, D. Kane, S. Lovett
                            </i>
                            <br> <a href="https://arxiv.org/abs/2302.06285">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2202.05444">Computational-Statistical Gaps in Reinforcement
                                Learning</a> <span class='options'> (COLT
                                2022) </span>
                            <br> <i>with D. Kane, S. Lui and S. Lovett
                            </i>
                            <br> <a href="https://arxiv.org/abs/2202.05444">arxiv</a> | <a
                                href="https://twitter.com/gauravmahajn/status/1493552416943312902">tweet</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2111.04746">Realizable Learning is All You Need</a> <span
                                class='options'> (COLT
                                2022) </span>
                            <br> <i>with M. Hopkins, D. Kane and S. Lovett
                            </i>
                            <br> <a href="https://arxiv.org/abs/2111.04746">arxiv</a> | <a
                                href="https://twitter.com/thegautamkamath/status/1458466857229373447">tweet</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2201.03806">Learning What To Remember</a> <span
                                class='options'> (ALT
                                2022) </span>
                            <br> <i>with R. Bhattacharjee</i>
                            <br> <a href="https://arxiv.org/abs/2201.03806">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2202.10640">Convergence of online k-means</a> <span
                                class='options'> (AISTATS
                                2022) </span>
                            <br> <i>with S. Dasgupta, G. So
                            </i>
                            <br>
                            <a href="https://arxiv.org/abs/2202.10640">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2103.10897">Bilinear Classes: A Structural Framework for
                                Provable Generalization in RL</a> <span class='options'> (ICML
                                2021) </span>
                            <br> <i> with S. S. Du, S. M. Kakade, J. D. Lee, S. Lovett, W. Sun, R.
                                <font color="red">(Long Talk)</font>
                            </i>
                            <br> <a href="http://proceedings.mlr.press/v139/du21a/du21a.pdf">icml</a> | <a
                                href="https://arxiv.org/abs/2103.10897">arxiv</a> | <a
                                href="https://twitter.com/CsabaSzepesvari/status/1437583932678082560">tweet</a> | <a
                                href="https://www.youtube.com/watch?v=OUJ-wP77VP0">talk</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="http://jmlr.org/papers/v22/19-736.html">On the Theory of Policy Gradient Methods:
                                Optimality, Approximation, and Distribution Shift</a> <span class='options'> (JMLR 2021)
                            </span>
                            <br> <i>with A. Agarwal, S. M. Kakade, J. D. Lee</i>
                            <br> <a href="http://jmlr.org/papers/v22/19-736.html">jmlr</a> | <a
                                href="https://arxiv.org/abs/1908.00261">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://ieeexplore.ieee.org/abstract/document/9317934">Point Location and Active
                                Learning: Learning Halfspaces Almost Optimally</a> <span class='options'> (FOCS
                                2020) </span>
                            <br> <i>with M. Hopkins, D. Kane, S. Lovett</i>
                            <br> <a href="https://ieeexplore.ieee.org/abstract/document/9317934">focs</a> | <a
                                href="https://arxiv.org/abs/2004.11380">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/1908.00261">Optimality and Approximation with Policy Gradient
                                Methods in Markov Decision
                                Processes</a> <span class='options'> (COLT
                                2020) </span>
                            <br> <i>with A. Agarwal, S. M. Kakade, J. D. Lee</i>
                            <br> <a href="http://proceedings.mlr.press/v125/agarwal20a.html">colt</a> | <a
                                href="https://arxiv.org/abs/1908.00261">arxiv</a> | <a
                                href="https://www.youtube.com/watch?v=tToomczBvMM&ab_channel=SimonsInstitute">sham's
                                talk</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2001.05497">Noise-tolerant, Reliable Active Classification
                                with Comparison Queries</a> <span class='options'> (COLT
                                2020) </span>
                            <br> <i>with M. Hopkins, D. Kane, S. Lovett</i>
                            <br><a href="https://arxiv.org/abs/2001.05497">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <a href="https://arxiv.org/abs/2002.07125">Q-learning with Function Approximation in
                                Deterministic Systems</a> <span class='options'> (NeurIPS 2020) </span>
                            <br> <i>with S. S. Du, J. D. Lee, R. Wang</i>
                            <br> <a href="https://arxiv.org/abs/2002.07125">arxiv</a> | <a
                                href="https://nips.cc/virtual/2020/protected/poster_fd5c905bcd8c3348ad1b35d7231ee2b1.html">talk</a>
                        </p>
                        <p></p>
                    </li>
                </ol>
                <br>
                <br>
                <br>
                <p id="footnote" style="padding: 20px 0px 50px 0px;"> &ast; Authors are listed in alphabetical order,
                    following the convention in mathematics
                    and theoretical computer science.</p>
            </div>
        </article>
    </main>
</body>

</html>