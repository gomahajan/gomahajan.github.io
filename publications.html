<!DOCTYPE html>
<html lang="en">

<head>
    <title>Gaurav Mahajan</title>
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic" rel="stylesheet" type="text/css">
    <link rel="stylesheet" type="text/css" href="css/style.css?v=3.1">
    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<body>
    <main>
        <div class="dtable">
            <div class="half pad20" style="height: 60px;">
                <a href="./">
                    <h1 class="top-header" style="font-weight: 500; margin: 0px;">Gaurav Mahajan</h1>
                </a>
                <div class="hidden" style="text-align: left;"> <b style="font-weight: 700;">Email:</b>
                    gaurav.mahajan@yale.edu</div><br>
            </div>
            <div class="hidden" style="float: left; padding: 15px 50px 0px 30px; width: 42%">
                <p style="text-align: right; margin: 5px;">
                    Room 339,<br> 17 Hillhouse Ave<br>
                    New Haven, CT 06511
                </p>
            </div>
        </div>
        <hr>
        <article class="margin50">
            <div style="width: fit-content;">
                <h1 id="select" style="margin: 50px 0px 0px 0px;">Selected Publications</h1>
                <ol>
                    <li>
                        <p>
                            <b>Learning Hidden Markov Models Using Conditional Samples</b>
                            <br> with S.M. Kakade, A. Krishnamurthy and C. Zhang
                            <br> COLT 2023
                            <br> <a href="https://arxiv.org/abs/2302.14753">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Exponential Hardness of Reinforcement Learning with Linear Function Approximation</b>
                            <br> with D. Kane, S. Liu, S. Lovett, C. Szepesvari and G. Weisz
                            <br> COLT 2023
                            <br> <a href="https://arxiv.org/abs/2302.12940">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Computational-Statistical Gaps in Reinforcement
                            Learning </b>
                            <br> with D. Kane, S. Lui and S. Lovett
                            <br> COLT 2022

                            <br> <a href="talks/ttic0607.mp4" target="_blank">
                                <font color="red">talk</font>
                            </a> | <a href="https://arxiv.org/abs/2202.05444">arxiv</a> | <a
                                href="https://twitter.com/gauravmahajn/status/1493552416943312902">tweet</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Optimality and Approximation with Policy Gradient Methods in Markov Decision
                                Processes</b>
                            <br> with A. Agarwal, S. M. Kakade, J. D. Lee
                            <br> COLT 2020
                            <br> <a href="http://proceedings.mlr.press/v125/agarwal20a.html">colt</a> | <a
                                href="https://arxiv.org/abs/1908.00261">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                </ol>
                <!-- <h1 style="margin: 50px 0px 0px 0px;">Full Publication List</h1> -->
                <h1 style="margin: 50px 0px 0px 0px;">All Publications</h1>
                <ol>
                    <li>
                        <p>
                            <b>Do PAC-Learners Learn the Marginal Distribution?</b>
                            <br> with M. Hopkins, D. Kane, S. Lovett
                            <br> Preprint
                            <br> <a href="https://arxiv.org/abs/2302.06285">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Learning Hidden Markov Models Using Conditional Samples</b>
                            <br> with S.M. Kakade, A. Krishnamurthy and C. Zhang
                            <br> COLT 2023
                            <br> <a href="https://arxiv.org/abs/2302.14753">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Exponential Hardness of Reinforcement Learning with Linear Function Approximation</b>
                            <br> with D. Kane, S. Liu, S. Lovett, C. Szepesvari and G. Weisz
                            <br> COLT 2023
                            <br> <a href="https://arxiv.org/abs/2302.12940">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Computational-Statistical Gaps in Reinforcement</b>
                            Learning
                            <br> with D. Kane, S. Lui and S. Lovett
                            <br> COLT 2022

                            <br> <a href="https://arxiv.org/abs/2202.05444">arxiv</a> | <a
                                href="https://twitter.com/gauravmahajn/status/1493552416943312902">tweet</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Realizable Learning is All You Need</b>
                            <br> with M. Hopkins, D. Kane and S. Lovett
                            <br> COLT
                            2022
                            <br> <a href="https://arxiv.org/abs/2111.04746">arxiv</a> | <a
                                href="https://twitter.com/thegautamkamath/status/1458466857229373447">tweet</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Point Location and Active
                                Learning: Learning Halfspaces Almost Optimally</b>
                            <br> with M. Hopkins, D. Kane, S. Lovett
                            <br> FOCS 2020
                            <br> <a href="https://ieeexplore.ieee.org/abstract/document/9317934">focs</a> | <a
                                href="https://arxiv.org/abs/2004.11380">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Optimality and Approximation with Policy Gradient Methods in Markov Decision
                                Processes</b>
                            <br> with A. Agarwal, S. M. Kakade, J. D. Lee
                            <br> COLT 2020
                            <br> <a href="http://proceedings.mlr.press/v125/agarwal20a.html">colt</a> | <a
                                href="https://arxiv.org/abs/1908.00261">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Noise-tolerant, Reliable Active Classification
                                with Comparison Queries</b>
                            <br> with M. Hopkins, D. Kane, S. Lovett
                            <br> COLT 2020
                            <br><a href="https://arxiv.org/abs/2001.05497">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Learning What To Remember</b>
                            <br> with R. Bhattacharjee
                            <br> ALT 2022
                            <br> <a href="https://arxiv.org/abs/2201.03806">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Convergence of online k-means</b>
                            <br> with S. Dasgupta, G. So
                            <br> AISTATS 2022
                            <br>
                            <a href="https://arxiv.org/abs/2202.10640">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Bilinear Classes: A Structural Framework for
                                Provable Generalization in RL</b>
                            <br> with S. S. Du, S. M. Kakade, J. D. Lee, S. Lovett, W. Sun, R. Wang
                            <br> ICML 2021 (Long Talk)
                            <br> <a href="http://proceedings.mlr.press/v139/du21a/du21a.pdf">icml</a> | <a
                                href="https://arxiv.org/abs/2103.10897">arxiv</a> | <a
                                href="https://twitter.com/CsabaSzepesvari/status/1437583932678082560">tweet</a> 
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>On the Theory of Policy Gradient Methods:
                                Optimality, Approximation, and Distribution Shift</b>
                            <br> with A. Agarwal, S. M. Kakade, J. D. Lee
                            <br> JMLR 2021
                            <br> <a href="http://jmlr.org/papers/v22/19-736.html">jmlr</a> | <a
                                href="https://arxiv.org/abs/1908.00261">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p>
                            <b>Q-learning with Function Approximation in
                                Deterministic Systems</b>
                            <br> with S. S. Du, J. D. Lee, R. Wang
                            <br> NeurIPS 2020
                            <br> <a href="https://arxiv.org/abs/2002.07125">arxiv</a>
                        </p>
                        <p></p>
                    </li>
                </ol>
                <h1 id="talk" style="margin: 50px 0px 0px 0px;">Talks</h1>
                <ol>
                    <li>
                        <p><b>Computational-Statistical Gaps in
                                Reinforcement Learning:</b>  <a href="talks/ttic0607.mp4" target="_blank">
                                    <font color="red">(talk)</font>
                                </a> <a href="slides/ttic.pdf" target="_blank">
                                    <font color="red">(slides)</font>
                                </a>

                            <br>Microsoft Research New York Seminar
                            <br>
                            Yale Foundations of Data Science Seminar
                            <br>
                            EnCORE Fall Retreat
                            <br>
                            TTIC Machine Learning Seminar Series
                            <br>
                            UCLA Big Data and Machine Learning weekly seminar
                            <br>
                            Brown Robotics Group (George
                            Konidaris's group)

                            <br> Berkeley RL Reading Group (Jiantao Jiao's group)

                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p><b> Equivalence between Realizable and Agnostic
                                Learning: </b> <a href="slides/cornell.pdf" target="_blank">
                                    <font color="red">(slides)</font>
                                </a>
                            <br> Cornell
                            Theory Seminar
                            <br>
                            MSR New York ML Reading Group
                        </p>
                        <p></p>
                    </li>
                    <li>
                        <p><b>Theory
                                of Generalization in Reinforcement Learning: </b> <a href="slides/rltheory.pdf" target="_blank">
                                    <font color="red">(slides)</font>
                                </a>
                            <br>
                            RL
                            Theory Seminar
                            <br>
                            UCSD AI
                            Seminar
                            <br>
                            UCSD
                            Theory
                            Seminar
                        </p>
                        <p></p>
                    </li>
                </ol>
                <h1 style="margin: 50px 0px 0px 0px;">Professional Services</h1>
                <ol>
                    <li>
                        Reviewer: ICLR (2022); WORLT (2021); Neurips (2021); ICML (2021, 2020), JMLR (2022, 2021,
                        2020)
                    </li>
                </ol>
                <br>
                <br>
                <br>
            </div>
        </article>
    </main>
</body>

</html>